{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-to-speech function using threading\n",
    "def speak(text):\n",
    "    def _speak():\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    threading.Thread(target=_speak).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shoulder abduction counter variables\n",
    "counter = 0\n",
    "stage = \"down\"\n",
    "rep_completed = False\n",
    "elbow_warning_issued = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746926106.995529  735576 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746926107.147157  736479 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746926107.170814  736476 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746926107.196476  736480 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Text-to-speech function using threading\n",
    "def speak(text):\n",
    "    def _speak():\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    threading.Thread(target=_speak).start()\n",
    "\n",
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Shoulder abduction counter variables\n",
    "counter = 0\n",
    "stage = \"down\"\n",
    "rep_completed = False\n",
    "elbow_warning_issued = False\n",
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Mediapipe pose instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract relevant joints\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angles\n",
    "            angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "            elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "            # Display shoulder angle\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(right_shoulder, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Elbow straightness check\n",
    "            if elbow_angle < 160:\n",
    "                if not elbow_warning_issued:\n",
    "                    alert_text = \"Straighten your elbow\"\n",
    "                    speak(alert_text)\n",
    "                    elbow_warning_issued = True\n",
    "                cv2.putText(image, \"Elbow bent\", (50, 150),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                elbow_warning_issued = False\n",
    "\n",
    "            # Shoulder abduction rep counter\n",
    "            if angle < 30:\n",
    "                stage = \"down\"\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Great job! You smashed your goal\"\n",
    "                        speak(message)\n",
    "                        cv2.putText(image, message, (50, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1000)\n",
    "                        break\n",
    "\n",
    "            elif angle > 170 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                rep_completed = True\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Draw UI\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Simple TensorFlow operation\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746925786.833628  732157 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746925786.983947  732450 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746925787.010957  732450 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746925787.235191  732446 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "Exception in thread Thread-4 (speech_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wasanotb/anaconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/wasanotb/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/wasanotb/anaconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/x7/61c4njbn7051yvyt806ym7740000gn/T/ipykernel_22189/2728982725.py\", line 23, in speech_loop\n",
      "  File \"/Users/wasanotb/anaconda3/lib/python3.11/site-packages/pyttsx3/engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "# Initialize mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Queue for text-to-speech messages\n",
    "speech_queue = Queue()\n",
    "\n",
    "# Background thread for speaking\n",
    "def speech_loop():\n",
    "    while True:\n",
    "        text = speech_queue.get()\n",
    "        if text is None:\n",
    "            break\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "        speech_queue.task_done()\n",
    "\n",
    "speech_thread = threading.Thread(target=speech_loop, daemon=True)\n",
    "speech_thread.start()\n",
    "\n",
    "# Function to enqueue speech\n",
    "def speak(text):\n",
    "    speech_queue.put(text)\n",
    "\n",
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Shoulder abduction counter variables\n",
    "counter = 0\n",
    "stage = \"down\"\n",
    "rep_completed = False\n",
    "elbow_warning_issued = False\n",
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Mediapipe pose instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract relevant joints\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angles\n",
    "            angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "            elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "            # Display shoulder angle\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(right_shoulder, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Elbow straightness check\n",
    "            if elbow_angle < 160:\n",
    "                if not elbow_warning_issued:\n",
    "                    speak(\"Straighten your elbow\")\n",
    "                    elbow_warning_issued = True\n",
    "                cv2.putText(image, \"Elbow bent\", (50, 150),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                elbow_warning_issued = False\n",
    "\n",
    "            # Shoulder abduction rep counter\n",
    "            if angle < 30:\n",
    "                stage = \"down\"\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Great job! You smashed your goal\"\n",
    "                        speak(message)\n",
    "                        cv2.putText(image, message, (50, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(2000)\n",
    "                        break\n",
    "\n",
    "            elif angle > 170 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                rep_completed = True\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Draw UI\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "    # Stop the speech thread\n",
    "    speech_queue.put(None)\n",
    "    speech_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746926339.321745  738785 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746926339.466760  739033 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746926339.489428  739033 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746926339.517027  739029 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n",
      "Rep: 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Text-to-speech function using threading\n",
    "def speak(text):\n",
    "    def _speak():\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    threading.Thread(target=_speak).start()\n",
    "\n",
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Shoulder abduction counter variables\n",
    "counter = 0\n",
    "stage = \"down\"\n",
    "rep_completed = False\n",
    "elbow_warning_issued = False\n",
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Mediapipe pose instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract relevant joints\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angles\n",
    "            angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "            elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "            # Display shoulder angle\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(right_shoulder, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Elbow straightness check\n",
    "            if elbow_angle < 160:\n",
    "                if not elbow_warning_issued:\n",
    "                    alert_text = \"Straighten your elbow\"\n",
    "                    # speak(alert_text)\n",
    "                    elbow_warning_issued = True\n",
    "                cv2.putText(image, \"Elbow bent\", (50, 150),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                elbow_warning_issued = False\n",
    "\n",
    "            # Shoulder abduction rep counter\n",
    "            if angle < 30:\n",
    "                stage = \"down\"\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Great job! You smashed your goal\"\n",
    "                        # speak(message)\n",
    "                        cv2.putText(image, message, (50, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1000)\n",
    "                        break\n",
    "\n",
    "            elif angle > 170 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                rep_completed = True\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Draw UI\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GLOG_minloglevel'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746962905.678747   38336 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746962905.796648   38662 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746962905.815377   38660 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1746962906.261848   38661 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Rep: 1\n",
      "Rep: 2\n",
      "Rep: 3\n",
      "Rep: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Calculate angle function\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Rep tracking\n",
    "counter = 0\n",
    "stage = None  # \"bent\" or \"straight\"\n",
    "\n",
    "# User input\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Process frame\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get left leg coordinates\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            angle = calculate_angle(hip, knee, ankle)\n",
    "\n",
    "            # Display angle\n",
    "            cv2.putText(image, f'{int(angle)}',\n",
    "                        tuple(np.multiply(knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Rep logic\n",
    "            if angle > 160:\n",
    "                if stage == \"bent\":\n",
    "                    stage = \"straight\"\n",
    "                    counter += 1\n",
    "                    print(f\"Rep: {counter}\")\n",
    "            elif angle < 100:\n",
    "                if stage != \"bent\":\n",
    "                    stage = \"bent\"\n",
    "\n",
    "            # Display rep count\n",
    "            cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "            cv2.putText(image, 'REPS', (15, 12),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Complete message\n",
    "            if counter >= target_reps:\n",
    "                cv2.putText(image, 'All reps done!', (200, 200),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('Knee Extension Tracker', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q') or counter >= target_reps:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746964283.028443   50292 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "W0000 00:00:1746964283.151485   50797 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746964283.169964   50797 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n",
      "Rep: 2\n",
      "Rep: 3\n",
      "Rep: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "# import pyttsx3\n",
    "# import threading\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# # Text-to-speech function using threading (موقّف الآن بالكومنت)\n",
    "# engine = pyttsx3.init()\n",
    "# def speak(text):\n",
    "#     def _speak():\n",
    "#         engine.say(text)\n",
    "#         engine.runAndWait()\n",
    "#     threading.Thread(target=_speak).start()\n",
    "\n",
    "# حساب الزاوية بين ثلاث نقاط\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - \\\n",
    "              np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# إعداد الكاميرا\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# عداد التكرارات\n",
    "counter = 0\n",
    "stage = None  # \"up\" or \"down\"\n",
    "rep_completed = False\n",
    "started = False  # <-- لضمان عدم العد مباشرة\n",
    "\n",
    "# عدد التكرارات المطلوبة\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# تشغيل Mediapipe Pose\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # التحويل إلى RGB للمعالجة\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # الرجوع إلى BGR للعرض\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # نقاط مفصل الرجل اليسرى\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # حساب الزاوية عند الركبة\n",
    "            angle = calculate_angle(hip, knee, ankle)\n",
    "\n",
    "            # عرض الزاوية على الشاشة\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # منطق العد: البداية عند الاستقامة\n",
    "            if angle > 150:\n",
    "                if not started:\n",
    "                    started = True  # تجاهل أول استقامة\n",
    "                else:\n",
    "                    stage = \"up\"\n",
    "                    rep_completed = True\n",
    "\n",
    "            # العد يتم عند العودة للانثناء\n",
    "            if angle < 120 and stage == \"up\":\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Excellent! Knee extension complete\"\n",
    "                        # speak(message)  # موقّف الآن\n",
    "                        cv2.putText(image, message, (30, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1500)\n",
    "                        break\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # مستطيل التكرار\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # رسم الجسم\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks,\n",
    "                                      mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # عرض الكاميرا\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# إغلاق الكاميرا والنوافذ\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# حساب الزاوية بين ثلاث نقاط\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - \\\n",
    "              np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# إعداد الكاميرا\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# عداد التكرارات\n",
    "counter = 0\n",
    "stage = None  # \"up\" or \"down\"\n",
    "rep_completed = False\n",
    "started = False  # <-- لضمان عدم العد مباشرة\n",
    "\n",
    "# عدد التكرارات المطلوبة\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# تشغيل Mediapipe Pose\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # التحويل إلى RGB للمعالجة\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # الرجوع إلى BGR للعرض\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # نقاط مفصل الرجل اليسرى\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # حساب الزاوية عند الركبة\n",
    "            angle = calculate_angle(hip, knee, ankle)\n",
    "\n",
    "            # عرض الزاوية على الشاشة\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # إذا كانت الزاوية صغيرة جداً فهذا يعني أنك في وضع الجلوس\n",
    "            if angle < 120 and not started:\n",
    "                started = True  # بدأنا في الجلوس\n",
    "\n",
    "            # منطق العد: البداية عند الاستقامة\n",
    "            if angle > 150 and started:\n",
    "                stage = \"up\"\n",
    "                rep_completed = True\n",
    "\n",
    "            # العد يتم عند العودة للانثناء\n",
    "            if angle < 120 and stage == \"up\":\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Excellent! Knee extension complete\"\n",
    "                        cv2.putText(image, message, (30, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1500)\n",
    "                        break\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # مستطيل التكرار\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # رسم الجسم\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks,\n",
    "                                      mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # عرض الكاميرا\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# إغلاق الكاميرا والنوافذ\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "لسا يحسب اول جلسة\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746977859.110615  135596 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746977859.246104  136271 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746977859.267514  136271 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746977860.266852  136267 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1   HIToolbox                           0x0000000189f145c8 _ZN15MenuBarInstance22EnsureAutoShowObserverEv + 120\n",
      "2   HIToolbox                           0x0000000189f14188 _ZN15MenuBarInstance14EnableAutoShowEv + 60\n",
      "3   HIToolbox                           0x0000000189e818bc _ZN15MenuBarInstance21UpdateAggregateUIModeE21MenuBarAnimationStylehhh + 1184\n",
      "4   HIToolbox                           0x0000000189f14004 _ZN15MenuBarInstance19SetFullScreenUIModeEjj + 180\n",
      "5   AppKit                              0x0000000183d03d30 -[NSApplication _setPresentationOptions:instance:flags:] + 956\n",
      "6   AppKit                              0x0000000183b9993c -[NSApplication _updateFullScreenPresentationOptionsForInstance:] + 404\n",
      "7   CoreFoundation                      0x00000001807b6560 __CFNOTIFICATIONCENTER_IS_CALLING_OUT_TO_AN_OBSERVER__ + 148\n",
      "8   CoreFoundation                      0x0000000180854044 ___CFXRegistrationPost_block_invoke + 88\n",
      "9   CoreFoundation                      0x0000000180853f8c _CFXRegistrationPost + 440\n",
      "10  CoreFoundation                      0x0000000180787b64 _CFXNotificationPost + 708\n",
      "11  Foundation                          0x000000018167738c -[NSNotificationCenter postNotificationName:object:userInfo:] + 88\n",
      "12  AppKit                              0x0000000183d042b4 spacesNotificationHandler + 96\n",
      "13  SkyLight                            0x00000001853f1214 _ZN12_GLOBAL__N_123notify_datagram_handlerEj15CGSDatagramTypePvmS1_ + 896\n",
      "14  SkyLight                            0x00000001853efe10 CGSSnarfAndDispatchDatagrams + 808\n",
      "15  SkyLight                            0x0000000185717a9c SLSGetNextEventRecordInternal + 344\n",
      "16  SkyLight                            0x0000000185518fb0 SLEventCreateNextEvent + 16\n",
      "17  HIToolbox                           0x0000000189eacb58 _ZL38PullEventsFromWindowServerOnConnectionjhP17__CFMachPortBoost + 60\n",
      "18  HIToolbox                           0x0000000189eacae0 _ZL14MessageHandlerP12__CFMachPortPvlS1_ + 60\n",
      "19  CoreFoundation                      0x00000001807f1410 __CFMachPortPerform + 260\n",
      "20  CoreFoundation                      0x00000001807c1f98 __CFRUNLOOP_IS_CALLING_OUT_TO_A_SOURCE1_PERFORM_FUNCTION__ + 60\n",
      "21  CoreFoundation                      0x00000001807c1eb8 __CFRunLoopDoSource1 + 520\n",
      "22  CoreFoundation                      0x00000001807c08a4 __CFRunLoopRun + 2264\n",
      "23  CoreFoundation                      0x00000001807bf878 CFRunLoopRunSpecific + 612\n",
      "24  HIToolbox                           0x0000000189e9ffa0 RunCurrentEventLoopInMode + 292\n",
      "25  HIToolbox                           0x0000000189e9fc30 ReceiveNextEventCommon + 236\n",
      "26  HIToolbox                           0x0000000189e9fb2c _BlockUntilNextEventMatchingListInModeWithFilter + 72\n",
      "27  AppKit                              0x0000000183a4584c _DPSNextEvent + 632\n",
      "28  AppKit                              0x0000000183a449dc -[NSApplication(NSEvent) _nextEventMatchingEventMask:untilDate:inMode:dequeue:] + 728\n",
      "29  cv2.abi3.so                         0x000000013d788768 cvWaitKey + 224\n",
      "30  cv2.abi3.so                         0x000000013d783388 _ZN2cv9waitKeyExEi + 236\n",
      "31  cv2.abi3.so                         0x000000013d78347c _ZN2cv7waitKeyEi + 48\n",
      "32  cv2.abi3.so                         0x000000013c9360bc _ZL19pyopencv_cv_waitKeyP7_objectS0_S0_ + 148\n",
      "33  python3.11                          0x0000000100b1c47c cfunction_call + 60\n",
      "34  python3.11                          0x0000000100bfe7b4 _PyEval_EvalFrameDefault + 194180\n",
      "35  python3.11                          0x0000000100bcc6ac _PyEval_Vector + 464\n",
      "36  python3.11                          0x0000000100bcc44c PyEval_EvalCode + 248\n",
      "37  python3.11                          0x0000000100bc7698 builtin_exec + 332\n",
      "38  python3.11                          0x0000000100c021d4 _PyEval_EvalFrameDefault + 209060\n",
      "39  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "40  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "41  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "42  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "43  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "44  python3.11                          0x0000000100ad7380 gen_send + 52\n",
      "45  python3.11                          0x0000000100acb8e8 method_vectorcall_O + 104\n",
      "46  python3.11                          0x0000000100bfe5c0 _PyEval_EvalFrameDefault + 193680\n",
      "47  python3.11                          0x0000000100aba174 _PyFunction_Vectorcall + 476\n",
      "48  python3.11                          0x0000000100abfe64 method_vectorcall + 272\n",
      "49  python3.11                          0x0000000100c0348c _PyEval_EvalFrameDefault + 213852\n",
      "50  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "51  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "52  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "53  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "54  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "55  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "56  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "57  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "58  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "59  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "60  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "61  _asyncio.cpython-311-darwin.so      0x00000001018e8370 task_step_impl + 440\n",
      "62  _asyncio.cpython-311-darwin.so      0x00000001018e8128 task_step + 68\n",
      "63  _asyncio.cpython-311-darwin.so      0x00000001018e8c30 task_wakeup + 136\n",
      "64  python3.11                          0x0000000100b1ce4c cfunction_vectorcall_O + 92\n",
      "65  python3.11                          0x0000000100c26b54 _PyObject_VectorcallTstate.4602 + 88\n",
      "66  python3.11                          0x0000000100c26a18 context_run + 92\n",
      "67  python3.11                          0x0000000100b1d12c cfunction_vectorcall_FASTCALL_KEYWORDS + 76\n",
      "68  python3.11                          0x0000000100c03538 _PyEval_EvalFrameDefault + 214024\n",
      "69  python3.11                          0x0000000100bcc6ac _PyEval_Vector + 464\n",
      "70  python3.11                          0x0000000100bcc44c PyEval_EvalCode + 248\n",
      "71  python3.11                          0x0000000100bc7698 builtin_exec + 332\n",
      "72  python3.11                          0x0000000100b1d12c cfunction_vectorcall_FASTCALL_KEYWORDS + 76\n",
      "73  python3.11                          0x0000000100bfe5c0 _PyEval_EvalFrameDefault + 193680\n",
      "74  python3.11                          0x0000000100aba174 _PyFunction_Vectorcall + 476\n",
      "75  python3.11                          0x0000000100c86da8 pymain_run_module + 212\n",
      "76  python3.11                          0x0000000100c86840 Py_RunMain + 1292\n",
      "77  python3.11                          0x0000000100a52ce0 main + 56\n",
      "78  dyld                                0x00000001803b7e50 start + 2544\n",
      "1   HIToolbox                           0x0000000189e9f90c _ZN15MenuBarInstance22RemoveAutoShowObserverEv + 44\n",
      "2   HIToolbox                           0x0000000189ede478 _ZL17BroadcastInternaljPvh + 184\n",
      "3   SkyLight                            0x00000001853f1214 _ZN12_GLOBAL__N_123notify_datagram_handlerEj15CGSDatagramTypePvmS1_ + 896\n",
      "4   SkyLight                            0x00000001853efe10 CGSSnarfAndDispatchDatagrams + 808\n",
      "5   SkyLight                            0x0000000185717a9c SLSGetNextEventRecordInternal + 344\n",
      "6   SkyLight                            0x0000000185518fb0 SLEventCreateNextEvent + 16\n",
      "7   HIToolbox                           0x0000000189eacb58 _ZL38PullEventsFromWindowServerOnConnectionjhP17__CFMachPortBoost + 60\n",
      "8   HIToolbox                           0x0000000189eacae0 _ZL14MessageHandlerP12__CFMachPortPvlS1_ + 60\n",
      "9   CoreFoundation                      0x00000001807f1410 __CFMachPortPerform + 260\n",
      "10  CoreFoundation                      0x00000001807c1f98 __CFRUNLOOP_IS_CALLING_OUT_TO_A_SOURCE1_PERFORM_FUNCTION__ + 60\n",
      "11  CoreFoundation                      0x00000001807c1eb8 __CFRunLoopDoSource1 + 520\n",
      "12  CoreFoundation                      0x00000001807c08a4 __CFRunLoopRun + 2264\n",
      "13  CoreFoundation                      0x00000001807bf878 CFRunLoopRunSpecific + 612\n",
      "14  HIToolbox                           0x0000000189e9ffa0 RunCurrentEventLoopInMode + 292\n",
      "15  HIToolbox                           0x0000000189e9fc30 ReceiveNextEventCommon + 236\n",
      "16  HIToolbox                           0x0000000189e9fb2c _BlockUntilNextEventMatchingListInModeWithFilter + 72\n",
      "17  AppKit                              0x0000000183a4584c _DPSNextEvent + 632\n",
      "18  AppKit                              0x0000000183a449dc -[NSApplication(NSEvent) _nextEventMatchingEventMask:untilDate:inMode:dequeue:] + 728\n",
      "19  cv2.abi3.so                         0x000000013d788768 cvWaitKey + 224\n",
      "20  cv2.abi3.so                         0x000000013d783388 _ZN2cv9waitKeyExEi + 236\n",
      "21  cv2.abi3.so                         0x000000013d78347c _ZN2cv7waitKeyEi + 48\n",
      "22  cv2.abi3.so                         0x000000013c9360bc _ZL19pyopencv_cv_waitKeyP7_objectS0_S0_ + 148\n",
      "23  python3.11                          0x0000000100b1c47c cfunction_call + 60\n",
      "24  python3.11                          0x0000000100bfe7b4 _PyEval_EvalFrameDefault + 194180\n",
      "25  python3.11                          0x0000000100bcc6ac _PyEval_Vector + 464\n",
      "26  python3.11                          0x0000000100bcc44c PyEval_EvalCode + 248\n",
      "27  python3.11                          0x0000000100bc7698 builtin_exec + 332\n",
      "28  python3.11                          0x0000000100c021d4 _PyEval_EvalFrameDefault + 209060\n",
      "29  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "30  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "31  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "32  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "33  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "34  python3.11                          0x0000000100ad7380 gen_send + 52\n",
      "35  python3.11                          0x0000000100acb8e8 method_vectorcall_O + 104\n",
      "36  python3.11                          0x0000000100bfe5c0 _PyEval_EvalFrameDefault + 193680\n",
      "37  python3.11                          0x0000000100aba174 _PyFunction_Vectorcall + 476\n",
      "38  python3.11                          0x0000000100abfe64 method_vectorcall + 272\n",
      "39  python3.11                          0x0000000100c0348c _PyEval_EvalFrameDefault + 213852\n",
      "40  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "41  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "42  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "43  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "44  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "45  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "46  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "47  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "48  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "49  python3.11                          0x0000000100bd9ae8 _PyEval_EvalFrameDefault + 43448\n",
      "50  python3.11                          0x0000000100ad6c28 gen_send_ex2 + 204\n",
      "51  _asyncio.cpython-311-darwin.so      0x00000001018e8370 task_step_impl + 440\n",
      "52  _asyncio.cpython-311-darwin.so      0x00000001018e8128 task_step + 68\n",
      "53  _asyncio.cpython-311-darwin.so      0x00000001018e8c30 task_wakeup + 136\n",
      "54  python3.11                          0x0000000100b1ce4c cfunction_vectorcall_O + 92\n",
      "55  python3.11                          0x0000000100c26b54 _PyObject_VectorcallTstate.4602 + 88\n",
      "56  python3.11                          0x0000000100c26a18 context_run + 92\n",
      "57  python3.11                          0x0000000100b1d12c cfunction_vectorcall_FASTCALL_KEYWORDS + 76\n",
      "58  python3.11                          0x0000000100c03538 _PyEval_EvalFrameDefault + 214024\n",
      "59  python3.11                          0x0000000100bcc6ac _PyEval_Vector + 464\n",
      "60  python3.11                          0x0000000100bcc44c PyEval_EvalCode + 248\n",
      "61  python3.11                          0x0000000100bc7698 builtin_exec + 332\n",
      "62  python3.11                          0x0000000100b1d12c cfunction_vectorcall_FASTCALL_KEYWORDS + 76\n",
      "63  python3.11                          0x0000000100bfe5c0 _PyEval_EvalFrameDefault + 193680\n",
      "64  python3.11                          0x0000000100aba174 _PyFunction_Vectorcall + 476\n",
      "65  python3.11                          0x0000000100c86da8 pymain_run_module + 212\n",
      "66  python3.11                          0x0000000100c86840 Py_RunMain + 1292\n",
      "67  python3.11                          0x0000000100a52ce0 main + 56\n",
      "68  dyld                                0x00000001803b7e50 start + 2544\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# حساب الزاوية بين ثلاث نقاط\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - \\\n",
    "              np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# إعداد الكاميرا\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# عداد التكرارات\n",
    "counter = 0\n",
    "stage = None  # \"up\" or \"down\"\n",
    "rep_completed = False\n",
    "started = False  # <-- لضمان عدم العد مباشرة\n",
    "\n",
    "# عدد التكرارات المطلوبة\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# تشغيل Mediapipe Pose\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # التحويل إلى RGB للمعالجة\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # الرجوع إلى BGR للعرض\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # نقاط مفصل الرجل اليسرى\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # حساب الزاوية عند الركبة\n",
    "            angle = calculate_angle(hip, knee, ankle)\n",
    "\n",
    "            # عرض الزاوية على الشاشة\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # إذا كانت الزاوية صغيرة جداً فهذا يعني أنك في وضع الجلوس\n",
    "            if angle < 120 and not started:\n",
    "                started = True  # بدأنا في الجلوس\n",
    "\n",
    "            # بعد أن نكون في وضع الجلوس، يمكننا بدء العد\n",
    "            if started:\n",
    "                # منطق العد: البداية عند الاستقامة\n",
    "                if angle > 150 and stage != \"up\":  # يجب أن نكون قد عدنا للتمدد\n",
    "                    stage = \"up\"\n",
    "                    rep_completed = True\n",
    "\n",
    "                # العد يتم عند العودة للانثناء\n",
    "                if angle < 120 and stage == \"up\":\n",
    "                    if rep_completed:\n",
    "                        counter += 1\n",
    "                        rep_completed = False\n",
    "                        print(f\"Rep: {counter}\")\n",
    "\n",
    "                        if counter >= target_reps:\n",
    "                            message = \"Excellent! Knee extension complete\"\n",
    "                            cv2.putText(image, message, (30, 200),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                            cv2.imshow('Mediapipe Feed', image)\n",
    "                            cv2.waitKey(1500)\n",
    "                            break\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # مستطيل التكرار\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # رسم الجسم\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks,\n",
    "                                      mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # عرض الكاميرا\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# إغلاق الكاميرا والنوافذ\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746964464.014027   51993 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746964464.133570   52256 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746964464.155170   52261 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746964464.181102   52256 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n",
      "Rep: 2\n",
      "Rep: 3\n",
      "Rep: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "# import pyttsx3\n",
    "# import threading\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# # Text-to-speech function using threading (موقّف الآن بالكومنت)\n",
    "# engine = pyttsx3.init()\n",
    "# def speak(text):\n",
    "#     def _speak():\n",
    "#         engine.say(text)\n",
    "#         engine.runAndWait()\n",
    "#     threading.Thread(target=_speak).start()\n",
    "\n",
    "# حساب الزاوية بين ثلاث نقاط\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - \\\n",
    "              np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# إعداد الكاميرا\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# عداد التكرارات\n",
    "counter = 0\n",
    "stage = None  # \"up\" or \"down\"\n",
    "rep_completed = False\n",
    "started = False  # <-- لضمان عدم العد مباشرة\n",
    "\n",
    "# عدد التكرارات المطلوبة\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# تشغيل Mediapipe Pose\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # التحويل إلى RGB للمعالجة\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # الرجوع إلى BGR للعرض\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # نقاط مفصل الرجل اليسرى\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # حساب الزاوية عند الركبة\n",
    "            angle = calculate_angle(hip, knee, ankle)\n",
    "\n",
    "            # عرض الزاوية على الشاشة\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # منطق العد: بداية الجلوس بعد تأكيد الاستقامة\n",
    "            if angle > 150:\n",
    "                if not started:\n",
    "                    started = True  # تجاهل أول استقامة\n",
    "                else:\n",
    "                    stage = \"up\"\n",
    "                    rep_completed = True\n",
    "\n",
    "            # العد يتم عند العودة للانثناء بشكل واضح (زاوية أقل من 120 درجة)\n",
    "            if angle < 120 and stage == \"up\":\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Excellent! Knee extension complete\"\n",
    "                        # speak(message)  # موقّف الآن\n",
    "                        cv2.putText(image, message, (30, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1500)\n",
    "                        break\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # مستطيل التكرار\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # رسم الجسم\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks,\n",
    "                                      mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # عرض الكاميرا\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# إغلاق الكاميرا والنوافذ\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# renad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746964060.015591   46097 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "W0000 00:00:1746964060.137165   48146 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746964060.155192   48146 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knee Angle: 178.23, Stage: down, Reps: 0\n",
      "Knee Angle: 178.72, Stage: up, Reps: 0\n",
      "Knee Angle: 178.71, Stage: up, Reps: 0\n",
      "Knee Angle: 178.87, Stage: up, Reps: 0\n",
      "Knee Angle: 178.98, Stage: up, Reps: 0\n",
      "Knee Angle: 178.78, Stage: up, Reps: 0\n",
      "Knee Angle: 178.90, Stage: up, Reps: 0\n",
      "Knee Angle: 178.99, Stage: up, Reps: 0\n",
      "Knee Angle: 179.26, Stage: up, Reps: 0\n",
      "Knee Angle: 179.26, Stage: up, Reps: 0\n",
      "Knee Angle: 179.40, Stage: up, Reps: 0\n",
      "Knee Angle: 179.53, Stage: up, Reps: 0\n",
      "Knee Angle: 179.52, Stage: up, Reps: 0\n",
      "Knee Angle: 179.60, Stage: up, Reps: 0\n",
      "Knee Angle: 179.54, Stage: up, Reps: 0\n",
      "Knee Angle: 179.65, Stage: up, Reps: 0\n",
      "Knee Angle: 179.63, Stage: up, Reps: 0\n",
      "Knee Angle: 179.47, Stage: up, Reps: 0\n",
      "Knee Angle: 179.41, Stage: up, Reps: 0\n",
      "Knee Angle: 179.43, Stage: up, Reps: 0\n",
      "Knee Angle: 179.39, Stage: up, Reps: 0\n",
      "Knee Angle: 179.42, Stage: up, Reps: 0\n",
      "Knee Angle: 179.40, Stage: up, Reps: 0\n",
      "Knee Angle: 179.46, Stage: up, Reps: 0\n",
      "Knee Angle: 179.57, Stage: up, Reps: 0\n",
      "Knee Angle: 179.62, Stage: up, Reps: 0\n",
      "Knee Angle: 179.74, Stage: up, Reps: 0\n",
      "Knee Angle: 179.95, Stage: up, Reps: 0\n",
      "Knee Angle: 179.73, Stage: up, Reps: 0\n",
      "Knee Angle: 179.76, Stage: up, Reps: 0\n",
      "Knee Angle: 179.50, Stage: up, Reps: 0\n",
      "Knee Angle: 179.35, Stage: up, Reps: 0\n",
      "Knee Angle: 179.37, Stage: up, Reps: 0\n",
      "Knee Angle: 179.15, Stage: up, Reps: 0\n",
      "Knee Angle: 178.76, Stage: up, Reps: 0\n",
      "Knee Angle: 177.97, Stage: up, Reps: 0\n",
      "Knee Angle: 177.50, Stage: up, Reps: 0\n",
      "Knee Angle: 177.64, Stage: up, Reps: 0\n",
      "Knee Angle: 177.28, Stage: up, Reps: 0\n",
      "Knee Angle: 177.70, Stage: up, Reps: 0\n",
      "Knee Angle: 178.29, Stage: up, Reps: 0\n",
      "Knee Angle: 178.76, Stage: up, Reps: 0\n",
      "Knee Angle: 177.55, Stage: up, Reps: 0\n",
      "Knee Angle: 177.98, Stage: up, Reps: 0\n",
      "Knee Angle: 177.98, Stage: up, Reps: 0\n",
      "Knee Angle: 178.55, Stage: up, Reps: 0\n",
      "Knee Angle: 178.67, Stage: up, Reps: 0\n",
      "Knee Angle: 179.82, Stage: up, Reps: 0\n",
      "Knee Angle: 179.02, Stage: up, Reps: 0\n",
      "Knee Angle: 178.92, Stage: up, Reps: 0\n",
      "Knee Angle: 177.75, Stage: up, Reps: 0\n",
      "Knee Angle: 178.35, Stage: up, Reps: 0\n",
      "Knee Angle: 178.26, Stage: up, Reps: 0\n",
      "Knee Angle: 178.52, Stage: up, Reps: 0\n",
      "Knee Angle: 178.89, Stage: up, Reps: 0\n",
      "Knee Angle: 178.78, Stage: up, Reps: 0\n",
      "Knee Angle: 178.89, Stage: up, Reps: 0\n",
      "Knee Angle: 179.02, Stage: up, Reps: 0\n",
      "Knee Angle: 179.07, Stage: up, Reps: 0\n",
      "Knee Angle: 179.19, Stage: up, Reps: 0\n",
      "Knee Angle: 179.17, Stage: up, Reps: 0\n",
      "Knee Angle: 179.29, Stage: up, Reps: 0\n",
      "Knee Angle: 179.47, Stage: up, Reps: 0\n",
      "Knee Angle: 179.66, Stage: up, Reps: 0\n",
      "Knee Angle: 179.07, Stage: up, Reps: 0\n",
      "Knee Angle: 179.06, Stage: up, Reps: 0\n",
      "Knee Angle: 178.98, Stage: up, Reps: 0\n",
      "Knee Angle: 178.93, Stage: up, Reps: 0\n",
      "Knee Angle: 178.73, Stage: up, Reps: 0\n",
      "Knee Angle: 179.11, Stage: up, Reps: 0\n",
      "Knee Angle: 179.75, Stage: up, Reps: 0\n",
      "Knee Angle: 179.93, Stage: up, Reps: 0\n",
      "Knee Angle: 179.64, Stage: up, Reps: 0\n",
      "Knee Angle: 179.88, Stage: up, Reps: 0\n",
      "Knee Angle: 179.73, Stage: up, Reps: 0\n",
      "Knee Angle: 179.90, Stage: up, Reps: 0\n",
      "Knee Angle: 179.84, Stage: up, Reps: 0\n",
      "Knee Angle: 179.77, Stage: up, Reps: 0\n",
      "Knee Angle: 179.67, Stage: up, Reps: 0\n",
      "Knee Angle: 179.67, Stage: up, Reps: 0\n",
      "Knee Angle: 179.56, Stage: up, Reps: 0\n",
      "Knee Angle: 179.46, Stage: up, Reps: 0\n",
      "Knee Angle: 179.22, Stage: up, Reps: 0\n",
      "Knee Angle: 179.48, Stage: up, Reps: 0\n",
      "Knee Angle: 179.88, Stage: up, Reps: 0\n",
      "Knee Angle: 179.48, Stage: up, Reps: 0\n",
      "Knee Angle: 179.66, Stage: up, Reps: 0\n",
      "Knee Angle: 179.07, Stage: up, Reps: 0\n",
      "Knee Angle: 179.52, Stage: up, Reps: 0\n",
      "Knee Angle: 178.99, Stage: up, Reps: 0\n",
      "Knee Angle: 175.40, Stage: up, Reps: 0\n",
      "Knee Angle: 171.63, Stage: up, Reps: 0\n",
      "Knee Angle: 169.19, Stage: up, Reps: 0\n",
      "Knee Angle: 82.58, Stage: up, Reps: 0\n",
      "Rep: 1\n",
      "Knee Angle: 52.35, Stage: down, Reps: 1\n",
      "Knee Angle: 28.78, Stage: down, Reps: 1\n",
      "Knee Angle: 82.16, Stage: down, Reps: 1\n",
      "Knee Angle: 143.89, Stage: down, Reps: 1\n",
      "Knee Angle: 168.92, Stage: down, Reps: 1\n",
      "Knee Angle: 167.11, Stage: up, Reps: 1\n",
      "Knee Angle: 114.82, Stage: up, Reps: 1\n",
      "Rep: 2\n",
      "Knee Angle: 119.50, Stage: down, Reps: 2\n",
      "Knee Angle: 129.20, Stage: down, Reps: 2\n",
      "Knee Angle: 112.24, Stage: down, Reps: 2\n",
      "Knee Angle: 176.41, Stage: down, Reps: 2\n",
      "Knee Angle: 178.79, Stage: up, Reps: 2\n",
      "Knee Angle: 171.98, Stage: up, Reps: 2\n",
      "Knee Angle: 177.06, Stage: up, Reps: 2\n",
      "Knee Angle: 176.23, Stage: up, Reps: 2\n",
      "Knee Angle: 176.75, Stage: up, Reps: 2\n",
      "Knee Angle: 170.03, Stage: up, Reps: 2\n",
      "Knee Angle: 171.94, Stage: up, Reps: 2\n",
      "Knee Angle: 174.55, Stage: up, Reps: 2\n",
      "Knee Angle: 175.96, Stage: up, Reps: 2\n",
      "Knee Angle: 173.84, Stage: up, Reps: 2\n",
      "Knee Angle: 168.26, Stage: up, Reps: 2\n",
      "Knee Angle: 159.17, Stage: up, Reps: 2\n",
      "Knee Angle: 159.75, Stage: up, Reps: 2\n",
      "Knee Angle: 178.36, Stage: up, Reps: 2\n",
      "Knee Angle: 175.90, Stage: up, Reps: 2\n",
      "Knee Angle: 166.30, Stage: up, Reps: 2\n",
      "Knee Angle: 164.16, Stage: up, Reps: 2\n",
      "Knee Angle: 172.09, Stage: up, Reps: 2\n",
      "Knee Angle: 167.37, Stage: up, Reps: 2\n",
      "Knee Angle: 167.83, Stage: up, Reps: 2\n",
      "Knee Angle: 170.14, Stage: up, Reps: 2\n",
      "Knee Angle: 169.85, Stage: up, Reps: 2\n",
      "Knee Angle: 175.88, Stage: up, Reps: 2\n",
      "Knee Angle: 173.14, Stage: up, Reps: 2\n",
      "Knee Angle: 171.57, Stage: up, Reps: 2\n",
      "Knee Angle: 176.34, Stage: up, Reps: 2\n",
      "Knee Angle: 178.09, Stage: up, Reps: 2\n",
      "Knee Angle: 170.47, Stage: up, Reps: 2\n",
      "Knee Angle: 173.24, Stage: up, Reps: 2\n",
      "Knee Angle: 174.87, Stage: up, Reps: 2\n",
      "Knee Angle: 177.40, Stage: up, Reps: 2\n",
      "Knee Angle: 176.40, Stage: up, Reps: 2\n",
      "Knee Angle: 172.42, Stage: up, Reps: 2\n",
      "Knee Angle: 174.35, Stage: up, Reps: 2\n",
      "Knee Angle: 171.72, Stage: up, Reps: 2\n",
      "Knee Angle: 169.79, Stage: up, Reps: 2\n",
      "Knee Angle: 163.90, Stage: up, Reps: 2\n",
      "Knee Angle: 160.67, Stage: up, Reps: 2\n",
      "Knee Angle: 158.93, Stage: up, Reps: 2\n",
      "Knee Angle: 177.34, Stage: up, Reps: 2\n",
      "Knee Angle: 172.98, Stage: up, Reps: 2\n",
      "Knee Angle: 171.61, Stage: up, Reps: 2\n",
      "Knee Angle: 176.72, Stage: up, Reps: 2\n",
      "Knee Angle: 179.18, Stage: up, Reps: 2\n",
      "Knee Angle: 179.77, Stage: up, Reps: 2\n",
      "Knee Angle: 179.68, Stage: up, Reps: 2\n",
      "Knee Angle: 178.99, Stage: up, Reps: 2\n",
      "Knee Angle: 178.08, Stage: up, Reps: 2\n",
      "Knee Angle: 177.23, Stage: up, Reps: 2\n",
      "Knee Angle: 179.66, Stage: up, Reps: 2\n",
      "Knee Angle: 178.90, Stage: up, Reps: 2\n",
      "Knee Angle: 178.86, Stage: up, Reps: 2\n",
      "Knee Angle: 177.90, Stage: up, Reps: 2\n",
      "Knee Angle: 174.51, Stage: up, Reps: 2\n",
      "Knee Angle: 175.36, Stage: up, Reps: 2\n",
      "Knee Angle: 174.99, Stage: up, Reps: 2\n",
      "Knee Angle: 169.76, Stage: up, Reps: 2\n",
      "Knee Angle: 167.97, Stage: up, Reps: 2\n",
      "Knee Angle: 171.05, Stage: up, Reps: 2\n",
      "Knee Angle: 175.12, Stage: up, Reps: 2\n",
      "Knee Angle: 174.43, Stage: up, Reps: 2\n",
      "Knee Angle: 174.89, Stage: up, Reps: 2\n",
      "Knee Angle: 178.68, Stage: up, Reps: 2\n",
      "Knee Angle: 178.46, Stage: up, Reps: 2\n",
      "Knee Angle: 175.34, Stage: up, Reps: 2\n",
      "Knee Angle: 176.97, Stage: up, Reps: 2\n",
      "Knee Angle: 178.43, Stage: up, Reps: 2\n",
      "Knee Angle: 179.07, Stage: up, Reps: 2\n",
      "Knee Angle: 178.80, Stage: up, Reps: 2\n",
      "Knee Angle: 174.25, Stage: up, Reps: 2\n",
      "Knee Angle: 173.68, Stage: up, Reps: 2\n",
      "Knee Angle: 177.19, Stage: up, Reps: 2\n",
      "Knee Angle: 175.75, Stage: up, Reps: 2\n",
      "Knee Angle: 175.39, Stage: up, Reps: 2\n",
      "Knee Angle: 173.76, Stage: up, Reps: 2\n",
      "Knee Angle: 175.60, Stage: up, Reps: 2\n",
      "Knee Angle: 175.88, Stage: up, Reps: 2\n",
      "Knee Angle: 174.97, Stage: up, Reps: 2\n",
      "Knee Angle: 172.95, Stage: up, Reps: 2\n",
      "Knee Angle: 173.08, Stage: up, Reps: 2\n",
      "Knee Angle: 172.98, Stage: up, Reps: 2\n",
      "Knee Angle: 170.36, Stage: up, Reps: 2\n",
      "Knee Angle: 170.18, Stage: up, Reps: 2\n",
      "Knee Angle: 169.10, Stage: up, Reps: 2\n",
      "Knee Angle: 171.43, Stage: up, Reps: 2\n",
      "Knee Angle: 173.54, Stage: up, Reps: 2\n",
      "Knee Angle: 174.07, Stage: up, Reps: 2\n",
      "Knee Angle: 175.42, Stage: up, Reps: 2\n",
      "Knee Angle: 177.09, Stage: up, Reps: 2\n",
      "Knee Angle: 176.44, Stage: up, Reps: 2\n",
      "Knee Angle: 175.99, Stage: up, Reps: 2\n",
      "Knee Angle: 175.26, Stage: up, Reps: 2\n",
      "Knee Angle: 174.93, Stage: up, Reps: 2\n",
      "Knee Angle: 173.78, Stage: up, Reps: 2\n",
      "Knee Angle: 174.58, Stage: up, Reps: 2\n",
      "Knee Angle: 174.19, Stage: up, Reps: 2\n",
      "Knee Angle: 173.45, Stage: up, Reps: 2\n",
      "Knee Angle: 167.40, Stage: up, Reps: 2\n",
      "Knee Angle: 165.83, Stage: up, Reps: 2\n",
      "Knee Angle: 160.04, Stage: up, Reps: 2\n",
      "Knee Angle: 157.71, Stage: up, Reps: 2\n",
      "Knee Angle: 114.70, Stage: up, Reps: 2\n",
      "Rep: 3\n",
      "Knee Angle: 152.58, Stage: down, Reps: 3\n",
      "Knee Angle: 159.04, Stage: up, Reps: 3\n",
      "Knee Angle: 167.96, Stage: up, Reps: 3\n",
      "Knee Angle: 167.27, Stage: up, Reps: 3\n",
      "Knee Angle: 170.45, Stage: up, Reps: 3\n",
      "Knee Angle: 174.06, Stage: up, Reps: 3\n",
      "Knee Angle: 174.16, Stage: up, Reps: 3\n",
      "Knee Angle: 174.49, Stage: up, Reps: 3\n",
      "Knee Angle: 174.89, Stage: up, Reps: 3\n",
      "Knee Angle: 175.22, Stage: up, Reps: 3\n",
      "Knee Angle: 175.73, Stage: up, Reps: 3\n",
      "Knee Angle: 176.14, Stage: up, Reps: 3\n",
      "Knee Angle: 177.01, Stage: up, Reps: 3\n",
      "Knee Angle: 176.26, Stage: up, Reps: 3\n",
      "Knee Angle: 175.42, Stage: up, Reps: 3\n",
      "Knee Angle: 174.33, Stage: up, Reps: 3\n",
      "Knee Angle: 173.22, Stage: up, Reps: 3\n",
      "Knee Angle: 172.80, Stage: up, Reps: 3\n",
      "Knee Angle: 172.10, Stage: up, Reps: 3\n",
      "Knee Angle: 171.52, Stage: up, Reps: 3\n",
      "Knee Angle: 173.01, Stage: up, Reps: 3\n",
      "Knee Angle: 174.74, Stage: up, Reps: 3\n",
      "Knee Angle: 175.87, Stage: up, Reps: 3\n",
      "Knee Angle: 176.12, Stage: up, Reps: 3\n",
      "Knee Angle: 177.22, Stage: up, Reps: 3\n",
      "Knee Angle: 177.69, Stage: up, Reps: 3\n",
      "Knee Angle: 177.78, Stage: up, Reps: 3\n",
      "Knee Angle: 177.76, Stage: up, Reps: 3\n",
      "Knee Angle: 177.87, Stage: up, Reps: 3\n",
      "Knee Angle: 178.46, Stage: up, Reps: 3\n",
      "Knee Angle: 178.36, Stage: up, Reps: 3\n",
      "Knee Angle: 177.70, Stage: up, Reps: 3\n",
      "Knee Angle: 178.22, Stage: up, Reps: 3\n",
      "Knee Angle: 178.79, Stage: up, Reps: 3\n",
      "Knee Angle: 179.84, Stage: up, Reps: 3\n",
      "Knee Angle: 179.74, Stage: up, Reps: 3\n",
      "Knee Angle: 178.29, Stage: up, Reps: 3\n",
      "Knee Angle: 178.46, Stage: up, Reps: 3\n",
      "Knee Angle: 177.84, Stage: up, Reps: 3\n",
      "Knee Angle: 177.38, Stage: up, Reps: 3\n",
      "Knee Angle: 177.80, Stage: up, Reps: 3\n",
      "Knee Angle: 178.56, Stage: up, Reps: 3\n",
      "Knee Angle: 178.55, Stage: up, Reps: 3\n",
      "Knee Angle: 178.38, Stage: up, Reps: 3\n",
      "Knee Angle: 178.36, Stage: up, Reps: 3\n",
      "Knee Angle: 176.99, Stage: up, Reps: 3\n",
      "Knee Angle: 176.50, Stage: up, Reps: 3\n",
      "Knee Angle: 176.82, Stage: up, Reps: 3\n",
      "Knee Angle: 174.05, Stage: up, Reps: 3\n",
      "Knee Angle: 174.38, Stage: up, Reps: 3\n",
      "Knee Angle: 174.88, Stage: up, Reps: 3\n",
      "Knee Angle: 175.16, Stage: up, Reps: 3\n",
      "Knee Angle: 173.91, Stage: up, Reps: 3\n",
      "Knee Angle: 174.86, Stage: up, Reps: 3\n",
      "Knee Angle: 176.34, Stage: up, Reps: 3\n",
      "Knee Angle: 178.27, Stage: up, Reps: 3\n",
      "Knee Angle: 178.59, Stage: up, Reps: 3\n",
      "Knee Angle: 179.25, Stage: up, Reps: 3\n",
      "Knee Angle: 178.95, Stage: up, Reps: 3\n",
      "Knee Angle: 179.40, Stage: up, Reps: 3\n",
      "Knee Angle: 178.56, Stage: up, Reps: 3\n",
      "Knee Angle: 178.27, Stage: up, Reps: 3\n",
      "Knee Angle: 178.36, Stage: up, Reps: 3\n",
      "Knee Angle: 178.49, Stage: up, Reps: 3\n",
      "Knee Angle: 178.10, Stage: up, Reps: 3\n",
      "Knee Angle: 177.85, Stage: up, Reps: 3\n",
      "Knee Angle: 177.74, Stage: up, Reps: 3\n",
      "Knee Angle: 177.74, Stage: up, Reps: 3\n",
      "Knee Angle: 177.48, Stage: up, Reps: 3\n",
      "Knee Angle: 177.06, Stage: up, Reps: 3\n",
      "Knee Angle: 177.41, Stage: up, Reps: 3\n",
      "Knee Angle: 177.43, Stage: up, Reps: 3\n",
      "Knee Angle: 177.42, Stage: up, Reps: 3\n",
      "Knee Angle: 176.95, Stage: up, Reps: 3\n",
      "Knee Angle: 176.94, Stage: up, Reps: 3\n",
      "Knee Angle: 176.72, Stage: up, Reps: 3\n",
      "Knee Angle: 176.70, Stage: up, Reps: 3\n",
      "Knee Angle: 176.59, Stage: up, Reps: 3\n",
      "Knee Angle: 176.56, Stage: up, Reps: 3\n",
      "Knee Angle: 176.52, Stage: up, Reps: 3\n",
      "Knee Angle: 176.54, Stage: up, Reps: 3\n",
      "Knee Angle: 176.53, Stage: up, Reps: 3\n",
      "Knee Angle: 176.25, Stage: up, Reps: 3\n",
      "Knee Angle: 176.13, Stage: up, Reps: 3\n",
      "Knee Angle: 176.11, Stage: up, Reps: 3\n",
      "Knee Angle: 176.16, Stage: up, Reps: 3\n",
      "Knee Angle: 176.05, Stage: up, Reps: 3\n",
      "Knee Angle: 175.82, Stage: up, Reps: 3\n",
      "Knee Angle: 175.80, Stage: up, Reps: 3\n",
      "Knee Angle: 175.61, Stage: up, Reps: 3\n",
      "Knee Angle: 175.55, Stage: up, Reps: 3\n",
      "Knee Angle: 175.80, Stage: up, Reps: 3\n",
      "Knee Angle: 175.99, Stage: up, Reps: 3\n",
      "Knee Angle: 175.90, Stage: up, Reps: 3\n",
      "Knee Angle: 175.95, Stage: up, Reps: 3\n",
      "Knee Angle: 175.81, Stage: up, Reps: 3\n",
      "Knee Angle: 175.75, Stage: up, Reps: 3\n",
      "Knee Angle: 175.72, Stage: up, Reps: 3\n",
      "Knee Angle: 175.68, Stage: up, Reps: 3\n",
      "Knee Angle: 175.62, Stage: up, Reps: 3\n",
      "Knee Angle: 175.49, Stage: up, Reps: 3\n",
      "Knee Angle: 175.43, Stage: up, Reps: 3\n",
      "Knee Angle: 175.16, Stage: up, Reps: 3\n",
      "Knee Angle: 175.03, Stage: up, Reps: 3\n",
      "Knee Angle: 175.03, Stage: up, Reps: 3\n",
      "Knee Angle: 174.97, Stage: up, Reps: 3\n",
      "Knee Angle: 174.91, Stage: up, Reps: 3\n",
      "Knee Angle: 174.88, Stage: up, Reps: 3\n",
      "Knee Angle: 174.85, Stage: up, Reps: 3\n",
      "Knee Angle: 174.80, Stage: up, Reps: 3\n",
      "Knee Angle: 174.95, Stage: up, Reps: 3\n",
      "Knee Angle: 175.11, Stage: up, Reps: 3\n",
      "Knee Angle: 175.12, Stage: up, Reps: 3\n",
      "Knee Angle: 175.30, Stage: up, Reps: 3\n",
      "Knee Angle: 175.27, Stage: up, Reps: 3\n",
      "Knee Angle: 175.30, Stage: up, Reps: 3\n",
      "Knee Angle: 175.32, Stage: up, Reps: 3\n",
      "Knee Angle: 175.47, Stage: up, Reps: 3\n",
      "Knee Angle: 175.46, Stage: up, Reps: 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "# import pyttsx3    # تم تعطيله\n",
    "# import threading  # تم تعطيله\n",
    "\n",
    "# === تهيئة Mediapipe ===\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# === دالة حساب الزاوية ===\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# === (تم تعطيل الصوت) ===\n",
    "# engine = pyttsx3.init()\n",
    "# def speak(text):\n",
    "#     def _speak():\n",
    "#         engine.say(text)\n",
    "#         engine.runAndWait()\n",
    "#     threading.Thread(target=_speak).start()\n",
    "\n",
    "# === بدء التقاط الفيديو ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# === متغيرات العد والمنطق ===\n",
    "counter = 0\n",
    "stage = \"down\"       # الحالة الابتدائية: ساق لأسفل\n",
    "rep_completed = False\n",
    "\n",
    "# سؤال المستخدم عن عدد التكرارات المستهدفة\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # تحويل للصورة لـ RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # إعادة BGR للرسم\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # استخراج مفاصل الساق اليمنى\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "            # حساب زاوية الركبة\n",
    "            angle = calculate_angle(hip, knee, ankle)\n",
    "\n",
    "            # عرض الزاوية على الصورة\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # طباعة الزاوية والحالة للتصحيح\n",
    "            print(f\"Knee Angle: {angle:.2f}, Stage: {stage}, Reps: {counter}\")\n",
    "\n",
    "            # منطق العد:\n",
    "            # 1) إذا زاوية > 150 → ساق مرفوعة → ضبط stage = \"up\"\n",
    "            if angle > 150:\n",
    "                stage = \"up\"\n",
    "                rep_completed = True\n",
    "\n",
    "            # 2) إذا زاوية < 120 و stage == \"up\" → ساق منثنية بعد الرفع → إضافة تكرار\n",
    "            if angle < 120 and stage == \"up\" and rep_completed:\n",
    "                counter += 1\n",
    "                rep_completed = False\n",
    "                stage = \"down\"\n",
    "                print(f\"Rep: {counter}\")\n",
    "                # speak(f\"{counter}\")  # صوت التكرار (معطل)\n",
    "\n",
    "                # عند انتهاء الهدف\n",
    "                if counter >= target_reps:\n",
    "                    message = \"Excellent! Knee extension complete\"\n",
    "                    # speak(message)  # صوت الإكتمال (معطل)\n",
    "                    cv2.putText(image, message, (50, 200),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                    cv2.imshow('Mediapipe Feed', image)\n",
    "                    cv2.waitKey(2000)\n",
    "                    break\n",
    "\n",
    "        # رسم واجهة العد\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # رسم النقاط والاتصالات\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        # إنهاء الضغط على 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# تحرير الموارد\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746965851.405945   62433 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746965851.526060   63574 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746965851.546512   63574 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746965851.978359   63579 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n",
      "Rep: 2\n",
      "Rep: 3\n",
      "Rep: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Text-to-speech function using threading\n",
    "def speak(text):\n",
    "    def _speak():\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    threading.Thread(target=_speak).start()\n",
    "\n",
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Knee extension counter variables\n",
    "counter = 0\n",
    "stage = \"bent\"\n",
    "rep_completed = False\n",
    "started = False  # To track if the first rep has started\n",
    "movement_stage = 0  # To track different stages of movement (0: standing, 1: sitting, 2: extended, 3: seated)\n",
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Mediapipe pose instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract left leg joints\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate knee angle\n",
    "            angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "\n",
    "            # Display angle on screen\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(left_knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Logic to detect movement stages\n",
    "            if angle > 160 and movement_stage == 0:  # Standing position\n",
    "                movement_stage = 1  # Transition to sitting\n",
    "            elif angle < 100 and movement_stage == 1:  # Sitting position\n",
    "                movement_stage = 2  # Transition to extension\n",
    "            elif angle > 160 and movement_stage == 2:  # Extended position (leg extended)\n",
    "                movement_stage = 3  # Transition to seated again\n",
    "            elif angle < 100 and movement_stage == 3:  # Seated again (back to small angle)\n",
    "                if started:  # If the first rep has already started\n",
    "                    counter += 1\n",
    "                    print(f\"Rep: {counter}\")\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Excellent! Knee extension complete\"\n",
    "                        # speak(message)\n",
    "                        cv2.putText(image, message, (50, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1000)\n",
    "                        break\n",
    "                else:  # If it's the first rep, start counting\n",
    "                    started = True\n",
    "                    counter += 1\n",
    "                    print(f\"Rep: {counter}\")\n",
    "                    movement_stage = 0  # Reset the movement stage to start again after rep\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Draw UI\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746966208.211162   66319 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746966208.332423   66625 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746966208.353126   66630 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746966208.378445   66626 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Text-to-speech function using threading\n",
    "def speak(text):\n",
    "    def _speak():\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    threading.Thread(target=_speak).start()\n",
    "\n",
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Knee extension counter variables\n",
    "counter = 0\n",
    "stage = \"bent\"\n",
    "rep_completed = False\n",
    "sequence_stage = 0  # Variable to track the sequence of movements\n",
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Mediapipe pose instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract left leg joints\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate knee angle\n",
    "            angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "\n",
    "            # Display angle on screen\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(left_knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Rep counter logic with sequence check\n",
    "            if sequence_stage == 0 and angle > 160:  # Standing position (large angle)\n",
    "                sequence_stage = 1\n",
    "            elif sequence_stage == 1 and angle < 100:  # Sitting position (small angle)\n",
    "                sequence_stage = 2\n",
    "            elif sequence_stage == 2 and angle > 160:  # Leg extension (large angle)\n",
    "                sequence_stage = 3\n",
    "            elif sequence_stage == 3 and angle < 100:  # Returning to sitting position (small angle)\n",
    "                sequence_stage = 0  # Reset to begin a new rep\n",
    "                \n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Excellent! Knee extension complete\"\n",
    "                        speak(message)\n",
    "                        cv2.putText(image, message, (50, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1000)\n",
    "                        break\n",
    "\n",
    "            # Update the rep_completed flag when the sequence is completed\n",
    "            if angle > 160 and sequence_stage == 0:\n",
    "                rep_completed = True\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Draw UI\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦵 Knee Extension Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746962239.201680   31631 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746962239.323791   31925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746962239.343516   31928 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746962239.493904   31927 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n",
      "Rep: 2\n",
      "Rep: 3\n",
      "Rep: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Text-to-speech function using threading\n",
    "def speak(text):\n",
    "    def _speak():\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    threading.Thread(target=_speak).start()\n",
    "\n",
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Knee extension counter variables\n",
    "counter = 0\n",
    "stage = \"bent\"\n",
    "rep_completed = False\n",
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Mediapipe pose instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract left leg joints\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate knee angle\n",
    "            angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "\n",
    "            # Display angle on screen\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(left_knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Rep counter logic\n",
    "            if angle < 100:\n",
    "                stage = \"bent\"\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Excellent! Knee extension complete\"\n",
    "                        # speak(message)\n",
    "                        cv2.putText(image, message, (50, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1000)\n",
    "                        break\n",
    "\n",
    "            elif angle > 160 and stage == \"bent\":\n",
    "                stage = \"straight\"\n",
    "                rep_completed = True\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Draw UI\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746929773.175900  753716 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "W0000 00:00:1746929773.304123  769453 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746929773.326713  769454 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_pose\u001b[38;5;241m.\u001b[39mPose(min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pose:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m---> 49\u001b[0m         ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m         frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;66;03m# Convert to RGB\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Text-to-speech function using threading\n",
    "def speak(text):\n",
    "    def _speak():\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    threading.Thread(target=_speak).start()\n",
    "\n",
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Knee extension counter variables\n",
    "counter = 0\n",
    "stage = \"down\"\n",
    "rep_completed = False\n",
    "elbow_warning_issued = False\n",
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Mediapipe pose instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract relevant joints\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate angles\n",
    "            angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "\n",
    "            # Display knee angle\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(right_knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Check for movement of hip and knee to avoid false counting\n",
    "            hip_y = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y\n",
    "            knee_y = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y\n",
    "\n",
    "            # Skip rep if the hip or knee has moved significantly (indicating you moved too much)\n",
    "            if hip_y < 0.4 or knee_y < 0.5:\n",
    "                continue  # Skip this frame, no rep counted\n",
    "\n",
    "            # Knee extension rep counter\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Great job! You smashed your goal\"\n",
    "                        # speak(message)\n",
    "                        cv2.putText(image, message, (50, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1000)\n",
    "                        break\n",
    "\n",
    "            elif angle < 30 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                rep_completed = True\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Draw UI\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746930000.263862  770981 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746930000.421479  771467 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746930000.443570  771466 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746930000.473575  771463 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n",
      "Rep: 2\n",
      "Rep: 3\n",
      "Rep: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe and text-to-speech\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Text-to-speech function using threading\n",
    "def speak(text):\n",
    "    def _speak():\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    threading.Thread(target=_speak).start()\n",
    "\n",
    "# Helper function to calculate angles\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Knee extension counter variables\n",
    "counter = 0\n",
    "stage = \"bent\"\n",
    "rep_completed = False\n",
    "\n",
    "# Ask user for number of reps\n",
    "target_reps = int(input(\"Enter number of reps: \"))\n",
    "\n",
    "# Mediapipe pose instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract left leg joints\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate knee angle\n",
    "            angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "\n",
    "            # Display angle on screen\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(left_knee, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Check for movement of hip and knee to avoid false counting\n",
    "            hip_y = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y\n",
    "            knee_y = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y\n",
    "\n",
    "            # Skip rep if the hip or knee has moved significantly (indicating you moved too much)\n",
    "            if hip_y < 0.4 or knee_y < 0.5:\n",
    "                continue  # Skip this frame, no rep counted\n",
    "\n",
    "            # Rep counter logic\n",
    "            if angle < 100:\n",
    "                stage = \"bent\"\n",
    "                if rep_completed:\n",
    "                    counter += 1\n",
    "                    rep_completed = False\n",
    "                    print(f\"Rep: {counter}\")\n",
    "\n",
    "                    if counter >= target_reps:\n",
    "                        message = \"Excellent! Knee extension complete\"\n",
    "                        speak(message)\n",
    "                        cv2.putText(image, message, (50, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        cv2.waitKey(1000)\n",
    "                        break\n",
    "\n",
    "            elif angle > 160 and stage == \"bent\":\n",
    "                stage = \"straight\"\n",
    "                rep_completed = True\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Draw UI\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'REPS', (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
